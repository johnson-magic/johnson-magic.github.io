<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="zhangteng">
  <title>Teng Zhang's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/zhangteng.jpg">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.‰∏ãËΩΩ"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://yangxue0827.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://yangxue0827.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#recent_works">Publications</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#preprints">Preprints</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#activities">Activities</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#projects">Projects</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./images/zhangteng.jpg">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Zhang Teng (Âº†ËÖæ)</h5>

        <hr>
        <h6 class="profile-link"><strong>Engineer</strong> at <a href="https://www.intsig.com/"><strong>Intsig</strong></a></h6>
        <h6 class="profile-link"><strong>Master</strong>, <a href="http://en.sjtu.edu.cn"><strong>Shanghai Jiao Tong University</strong></a></h6>
        <h6 class="profile-link"><strong>Address</strong>: No. 1268 Wanrong Road, Jing'an District, Shanghai</h6>
        <h6 class="profile-link"><strong>Email</strong>: zhangteng@sjtu.edu.cn, magic_zhang@intsig.net</h6>
        
        <h1></h1>
        
        <a href="https://scholar.google.com.hk/citations?user=T2veFc4AAAAJ&hl=en" target="_blank"><img class="responsive-img social-photo " src="./images/google_scholar.jpg"></a>
        
        <a href="https://johnson-magic.github.io/" target="_blank"><img class="responsive-img social-photo " src="./images/github.jpg"></a>

        <a href="./files/YangXue-CV.pdf" target="_blank"><img class="responsive-img social-photo " src="./images/cv.png"></a>

        <a href="./images/Wechat_QR_code.jpg" target="_blank"><img class="responsive-img social-photo " src="./images/wechat.png"></a>

        <a href="https://www.zhihu.com/people/flyyoung-68" target="_blank"><img class="responsive-img social-photo " src="./images/zhihu1.png"></a>

        <a href="https://www.linkedin.com/in/%E5%AD%A6-%E6%9D%A8-43065a1b4/" target="_blank"><img class="responsive-img social-photo " src="./images/linkedin.png"></a>

        <a href="https://www.researchgate.net/profile/Xue_Yang87" target="_blank"><img class="responsive-img social-photo " src="./images/rg.png"></a>
    
    </div>    
  
  </div>
  
  <div class="parallax"><img src="./images/homepage_bg1.jpeg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>  

</div>



<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">üá®üá≥ Biography</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        Xue Yang is now a Researcher at  <a href="https://opengvlab.shlab.org.cn/">OpenGVLab</a>, <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>, collaborated with <a href="https://scholar.google.com.hk/citations?user=SH_-B_AAAAAJ">Prof. Jifeng Dai</a> and <a href="https://scholar.google.com/citations?hl=zh-CN&user=02RXI00AAAAJ">Dr. Xizhou Zhu</a>. Xue Yang's research interests include deep learning and computer vision, with a focus on generic/oriented object detection/instance segmentation, AI Agent, Vision-Language Models. 
      </p>
      <p>
        Xue Yang received the B. E. degree from School of Information Science and Engineering, <a href="http://www.csu.edu.cn/">Central South University</a>, Hunan, China, in 2016. He received the M. S. degree from <a href="https://eece.ucas.ac.cn/index.php/zh-cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a><!--  (<a href="http://aircas.ac.cn/">Institute of Electrics, Chinese Academy of Sciences</a>) -->, Beijing, China, in 2019. Xue Yang obtained the Ph.D. degree from <a href="https://news.sjtu.edu.cn/jdyw/20190930/111855.html">Wu Honor Class</a> (<a href="https://xsb.seiee.sjtu.edu.cn/xsb/info/35105.htm">Âê¥Êñá‰øä‰∫∫Â∑•Êô∫ËÉΩÂçöÂ£´Áè≠</a>), <a href="http://www.cs.sjtu.edu.cn">Department of Computer Science and Engineering</a>, <a href="http://en.sjtu.edu.cn">Shanghai Jiao Tong University</a>, Shanghai, China, in 2023. His research advisor is <a href="http://thinklab.sjtu.edu.cn/">Prof. Junchi Yan</a>.
      </p>
      <p>
        Xue Yang has published about 30 papers <a href="https://scholar.google.com/citations?user=2xTlvV0AAAAJ&hl=en"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&amp;url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyangxue0827%2Fyangxue0827.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=citations" /></a> at the top international CV/ML/AI conferences and journals, such as TPAMI, IJCV, CVPR, ECCV, ICCV, ICML, NeurIPS, ICLR, AAAI and ACM MM. He is also the leading contributor to the <a href="https://github.com/open-mmlab/mmrotate">MMRotate</a> <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" /> and <a href="https://github.com/yangxue0827/RotationDetection">AlphaRotate</a> <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" /> open-source projects for oriented object detection, and with 8000+ stars in Github. 
        Xue Yang won <a href="https://www.ccf.org.cn/Membership/Individual_member/Honor/yxbsxwlwjljh/2024-01-05/811519.shtml" target="_blank">CCF Outstanding Doctoral Dissertation Award</a> (2023), <a href="https://mp.weixin.qq.com/s/mUgpVmyvCHdo5-T6-u8Yxg">CCF-CV Academic Emerging Scholar</a> (2022), <a href="https://www.seiee.sjtu.edu.cn/xsgz_tzgg_zyfz/7915.html" target="_blank">Shanghai Outstanding Graduates</a>, <a href="https://mp.weixin.qq.com/s/liVosHsotD2zDMyfmTIQJg" target="_blank">Doctoral National Scholarship</a> (2021/2022), <a href="https://mp.weixin.qq.com/s/hr7qtx3OUffSGS9qUhqc9w" target="_blank">SJTU Scholar Star Nomination Award</a> (2021), and also selected into the <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6">World's Top 2% Scientists 2022/2023 List</a>.
      </p>

      <p>
      <font color="red">
      <i>
        <b>Looking for self-motivated collaborators with the goal of publishing Top-Tier papers on the topic of remote sensing image interpretation, including but not limited to weakly-/semi-supervised oriented object detection. Please do not hesitate to contact me via email or WeChat</b>
      </i>
      </font>
      </p>
      <!-- <p>
      <font color="red">
        <i>
          I am also looking for a full-time job. 
        </i>
      </font>
      </p> -->
  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div class="section news-section scrollspy" id="news">

  <div class="row container">
    <div class="row">
      <div class="title">üî• News</div>
      <hr>
    </div>
    <div class="row">
      <ul>
        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 01 / 2023: &nbsp; <font color="red"> Happy Chinese New Year! </font>
        </li> -->

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2023: &nbsp; I'm awarded the <a href="https://mp.weixin.qq.com/s/Hk8iKReAUJVB_CraXqWYKg" target="_blank">CCF Doctoral Dissertation Award</a>, nine winners in China <a href="https://mp.weixin.qq.com/s/8wLaq2SvYF6zPbf_UFI_XQ">[CCF ‰ºòÁßÄÂçöÂ£´Â≠¶‰ΩçËÆ∫ÊñáÊøÄÂä±ËÆ°ÂàíÔºåÂÖ®ÂõΩ‰πù‰∫∫]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2023: &nbsp; One paper on oriented object detection (AlphaRotate) is accepted by <b>ICASSP 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 11 / 2023: &nbsp; I'm selected into the <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6">World's Top 2% Scientists 2022/2023 List</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 10 / 2023: &nbsp; I'm elected as CSIG-BVD Committee Member at PRCV 2023
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2023: &nbsp; One paper on oriented object detection (H2RBox-v2) is accepted by <b>NeurIPS 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2023: &nbsp; One collaborative paper on self-supervised text recognition (CCD) is accepted by <b>ICCV 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2023: &nbsp; Researcher at OpenGVLab, Shanghai AI Laboratory, working with <a href="https://scholar.google.com.hk/citations?user=SH_-B_AAAAAJ&hl=en">Prof. Jifeng Dai</a> and <a href="https://scholar.google.com/citations?hl=zh-CN&user=02RXI00AAAAJ">Dr. Xizhou Zhu</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 06 / 2023: &nbsp; A report is made at the Valse 2023 Wuxi <a href="http://valser.org/2023/#/workshop" target="_blank">[Valse 2023 Êó†Èî°, W2ÔºöÈÅ•ÊÑüÂΩ±ÂÉèËß£ËØë]</a>, <a href="./files/VALSE 2023 Wuxi.pdf" target="_blank">[Êä•ÂëäPPT]</a>, <a href="https://www.bilibili.com/video/BV1yu4y1R7f6/?spm_id_from=333.788&vd_source=be89b0c65eab470db155c6731fcffddf">[Êä•ÂëäÂõûÊîæ]</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 05 / 2023: &nbsp; I'm awarded the <a href="https://www.seiee.sjtu.edu.cn/xsgz_tzgg_zyfz/7915.html" target="_blank">Shanghai Outstanding Graduates</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 05 / 2023: &nbsp; Passed the doctoral dissertation defense <a href="https://drive.google.com/file/d/1xEgDcKrW7BeRkDHRX-aXmhUUow2TlfZ2/view?usp=share_link">[dissertation]</a>, <a href="https://drive.google.com/file/d/1uwGQ0AqpYmgg-6bPpLZ22o17sktdk4dL/view?usp=share_link">[slides]</a>, <a href="https://drive.google.com/file/d/1wns-nIUeXifKMJ2EQyhNbKDPpQWjK3wa/view?usp=share_link">[playback]</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 03 / 2023: &nbsp; Jittor implementation of CSL and RSDet are supported in <a href="https://github.com/Jittor/JDet" target="_blank">JDet</a> <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 03 / 2023: &nbsp; A report is made at OpenMMLab <a href="https://mp.weixin.qq.com/s/eoSxS64EtyF8FRMd3BlS-w" target="_blank">[OpenMMLabÁ§æÂå∫ÂºÄÊîæÈ∫¶]</a>, <a href="./files/OpenMMLabÂºÄÊîæÈ∫¶20230302.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1GD4y1g7s8" target="_blank">[bilibili]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GD4y1g7s8" />, <a href="https://www.zhihu.com/zvideo/1614738654315995136" target="_blank">[zhihu]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1614738654315995136" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2023: &nbsp; Research internship at OpenGVLab, Shanghai AI Laboratory, working with <a href="https://scholar.google.com.hk/citations?user=SH_-B_AAAAAJ&hl=en">Prof. Jifeng Dai</a> and <a href="https://scholar.google.com/citations?hl=zh-CN&user=02RXI00AAAAJ">Dr. Xizhou Zhu</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2023: &nbsp; One collaborative paper on text recognition (SIGA) is accepted by <b>CVPR 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2023: &nbsp; One paper on oriented object detection is accepted by SCIENTIA SINICA Informationis <a href="http://engine.scichina.com/doi/10.1360/SSI-2022-0410"><b>„Ää‰∏≠ÂõΩÁßëÂ≠¶Ôºö‰ø°ÊÅØÁßëÂ≠¶„Äã</b></a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 01 / 2023: &nbsp; One collaborative paper on oriented object detection (G-Rep) is accepted by <b>Remote Sensing</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 01 / 2023: &nbsp; Three papers on rotation detection (H2RBox, KFIoU), instance segmentation (PatchDCT) are accepted by <b>ICLR 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 01 / 2023: &nbsp; One collaborative paper on oriented object detection (TIOE) is accepted by <b>ISPRS</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2022: &nbsp; A report is made at the Doctoral Forum of PRCV 2022 <a href="https://m.inmuu.com/v1/live/news/2265574?gatherId=4043" target="_blank">[PRCV 2022 ÂçöÂ£´ÁîüËÆ∫Âùõ]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2022: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/mUgpVmyvCHdo5-T6-u8Yxg">CCF-CV Academic Emerging Scholar</a>, three winners in China <a href="https://tc.ccf.org.cn/ccfcv/xgzy/timing/2021-05-04/697856.shtml">[CCF-CV Â≠¶ÊúØÊñ∞ÈîêÂ≠¶ËÄÖÔºåÂÖ®ÂõΩ‰∏â‰∫∫]</a>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 11 / 2022: &nbsp; Jittor implementation of GWD, KLD, KFIoU and H2RBox are supported in <a href="https://github.com/Jittor/JDet" target="_blank">JDet</a> <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 11 / 2022: &nbsp; One collaborative paper on oriented object detection (PVT-SAR) is accepted by <b>JSTARS</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2022: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/liVosHsotD2zDMyfmTIQJg" target="_blank">Doctoral National Scholarship</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 08 / 2022: &nbsp; üéâüéâ My <a href="https://scholar.google.com/citations?user=2xTlvV0AAAAJ&hl=en">google scholar</a> citations have exceeded 2000!
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 08 / 2022: &nbsp; One paper on oriented object detection is accepted by <b>TPAMI</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2022: &nbsp; A report is made at OpenMMLab <a href="https://mp.weixin.qq.com/s/-_x4URDyhwqNC4mD_0daDw" target="_blank">[OpenMMLabÁ§æÂå∫ÂºÄÊîæÈ∫¶]</a>, <a href="./files/OpenMMLabÂºÄÊîæÈ∫¶.pdf" target="_blank">[slides]</a>, <a href="./files/OpenMMLabÂºÄÊîæÈ∫¶.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[bilibili]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />, <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[zhihu]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 06 / 2022: &nbsp; <a href="https://github.com/open-mmlab/mmrotate">MMRotate</a> is accepted by <b>ACM MM 2022</b> as <b>Oral</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 06 / 2022: &nbsp; A report is made at Young Scholars Forum of Wu Wenjun's artificial intelligence doctoral class <a href="https://mp.weixin.qq.com/s/lg1vNIZYqnDfq9SC93OT3A" target="_blank">[Âê¥Áè≠Talk]</a>, <a href="./files/Âê¥Áè≠Talk.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 06 / 2022: &nbsp; One collaborative paper on oriented object detection (RSDet++) is accepted by <b>TCSVT</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 04 / 2022: &nbsp; One paper on oriented object detection (SCRDet++) is accepted by <b>TPAMI</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 03 / 2022: &nbsp; One collaborative paper on image inpainting is accepted by <b>CVPR 2022</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2022: &nbsp; A PyTorch-based oriented object detection benchmark is released, called <a href="https://github.com/open-mmlab/mmrotate">MMRotate</a> <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2022: &nbsp; Research internship at EI Innovation Lab, Huawei Cloud, Shanghai, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=en">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=en">Dr. Xiaopeng Zhang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 02 / 2022: &nbsp; One paper on oriented object detection is accepted by <b>IJCV</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2021: &nbsp; I'm nominated by <a href="https://mp.weixin.qq.com/s/hr7qtx3OUffSGS9qUhqc9w" target="_blank">SJTU Scholar Star 2021</a>, <a href="https://mp.weixin.qq.com/s/hd7KKoc5u7Wd2R4PdYi-DQ" target="_blank">[‰∏äÊµ∑‰∫§ÈÄöÂ§ßÂ≠¶‚ÄúÂ≠¶ÊúØ‰πãÊòü‚ÄùÊèêÂêçÂ•ñ]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2021: &nbsp; A report is made at the fifth Jittor Forum <a href="https://mp.weixin.qq.com/s/8pYzCYU25B8Zzk78NBoovw" target="_blank">[Á¨¨‰∫îÊúü‚ÄúËÆ°Âõæ‚ÄùËÆ∫Âùõ]</a>, <a href="./files/ËÆ°ÂõæËÆ∫Âùõ.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 10 / 2021: &nbsp; Ranking in the Top 40 in the ninth <a href="./files/baidu_scholarship.jpg" target="_blank">Baidu Scholarship</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2021: &nbsp; One paper on oriented object detection (KLD) is accepted by <b>NeurIPS 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2021: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/ugk1l0QpuzJXaExJ_wH-4w" target="_blank">Doctoral National Scholarship (Top-1 in CSE)</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2021: &nbsp; One collaborative paper on oriented object detection (RIDet) is accepted by <b>GRSL</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2021: &nbsp; One collaborative paper on image inpainting is accepted by <b>ICCV 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2021: &nbsp; One collaborative paper on oriented object detection (SLA) is accepted by <b>Remote Sensing</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 05 / 2021: &nbsp; A report is made at the Magnolia Young Scholar Forum <a href="https://www.slidestalk.com/w/409" target="_blank">[ÁôΩÁéâÂÖ∞ÈùíÂπ¥Â≠¶ËÄÖËÆ∫Âùõ]</a>, <a href="./files/ÊóãËΩ¨ÁõÆÊ†áÊ£ÄÊµã-ÁôΩÁéâÂÖ∞ÈùíÂπ¥Â≠¶ËÄÖËÆ∫Âùõ.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 05 / 2021: &nbsp; One paper on oriented object detection (GWD) is accepted by <b>ICML 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 03 / 2021: &nbsp; One paper on oriented object detection (DCL) is accepted by <b>CVPR 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 12 / 2020: &nbsp; Two papers (one collaborative paper) on oriented object detection (R<sup>3</sup>Det, RSDet) are accepted by <b>AAAI 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 10 / 2020: &nbsp; A TensorFlow-based oriented object detection benchmark is released, called <a href="https://github.com/yangxue0827/RotationDetection">AlphaRotate</a> <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 10 / 2020: &nbsp; Research internship at EI Innovation Lab, Huawei, Shenzhen, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=en">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=en">Dr. Xiaopeng Zhang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2020: &nbsp; One paper on oriented object detection (CSL) is accepted by <b>ECCV 2020</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2019: &nbsp; I'm supported by <a href="https://ai.sjtu.edu.cn/info/news/126">Wu Wen Jun Honorary Doctoral Scholarship</a>, AI Institute, Shanghai Jiao Tong University
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 09 / 2019: &nbsp; I'm joining Department of CSE at Shanghai Jiao Tong University as a Ph.D. student, supervised by <a href="http://thinklab.sjtu.edu.cn/">Prof. Junchi Yan</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          ‚Ä¢ 07 / 2019: &nbsp; One paper on oriented object detection (SCRDet) is accepted by <b>ICCV 2019</b>
        </li>

        <div align='right'> <a href="./news.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div>

      </ul>
    </div>
  </div>
</div>


<!--==========================================
                   Recent Works
===========================================-->
<div class="section preprints-section scrollspy" id="recent_works">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Recent Works <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>*</sup> indicates equal contribution, <sup>‚Ä†</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./auto_mc-reward_files/pipeline_v3.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft</div>
          <div class="paper-author">Hao Li<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Zhaokai Wang<sup>*</sup>, Xizhou Zhu, Jie Zhou, Yu Qiao, Xiaogang Wang, Hongsheng Li, Lewei Lu, Jifeng Dai<sup>‚Ä†</sup></div>
          <div>
            <a href="https://arxiv.org/abs/2312.09238" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2312.09238-B31B1B.svg" /></a>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:ldfaerwXgEUC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ldfaerwXgEUC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ldfaerwXgEUC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
              <img class="responsive-img icon" src="./images/homepage.png">
              <a href="./auto_mc-reward.html.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/point2rbox.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision</div>
          <div class="paper-author">Yi Yu<sup>*</sup>, <font color="#0000dd"><b>Xue Yang</b><sup>*</sup></font>, Qingyun Li, Feipeng Da<sup>‚Ä†</sup>, Junchi Yan<sup>‚Ä†</sup>, Jifeng Dai, Yu Qiao</div>
          <div>
            <a href="https://arxiv.org/abs/2311.14758" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.14758-B31B1B.svg" /></a>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:2P1L_qKh6hAC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:2P1L_qKh6hAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:2P1L_qKh6hAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[Point2RBox-MMRotate]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/668627776" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/pointobb.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">PointOBB: Learning Oriented Object Detection via Single Point Supervision</div>
        <div class="paper-author">Junwei Luo, <font color="#0000dd"><b>Xue Yang</b><sup>#</sup></font>, Yu Yi, Qingyun Li, Junchi Yan, Yansheng Li<sup>‚Ä†</sup></div>
        <div>
          <a href="https://arxiv.org/abs/2311.14757" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.14757-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:70eg2SAEIzsC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:70eg2SAEIzsC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:70eg2SAEIzsC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/Luo-Z13/pointobb?style=social" />
          <a href="https://github.com/Luo-Z13/pointobb" target="_blank">[PointOBB-Pytorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/668792405" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
  </div>

  <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/p2rbox.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">P2RBox: A Single Point is All You Need for Oriented Object Detection</div>
        <div class="paper-author">Guangming Cao<sup>*</sup>, Xuehui Yu<sup>*</sup>, Wenwen Yu, Xumeng Han, <font color="#0000dd"><b>Xue Yang</b></font>, Guorong Li, Jianbin Jiao, Zhenjun Han<sup>‚Ä†</sup></div>
        <div>
          <a href="https://arxiv.org/abs/2311.13128" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.13128-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:35N4QoGY0k4C" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:35N4QoGY0k4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:35N4QoGY0k4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

  </div>

</div>

<!--==========================================
              LLMs and AI Agent
===========================================-->
<div class="section preprints-section scrollspy" id="llms_and_agent">

  <div class="row container">
    <div class="row">
      <div class="title">üìù LLMs and AI Agent <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/iGPT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</div>
        <div class="paper-author">Zhaoyang Liu<sup>*</sup>, Yinan He<sup>*</sup>, Wenhai Wang<sup>*</sup>, Weiyun Wang<sup>*</sup>, Yi Wang<sup>*</sup>, Shoufa Chen<sup>*</sup>, Qinglong Zhang<sup>*</sup>, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, Zhe Chen, <font color="#0000dd"><b>Xue Yang</b></font>, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao</div>
        <div>
          <a href="https://arxiv.org/abs/2305.05662" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2305.05662-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:RGFaLdJalmkC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RGFaLdJalmkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RGFaLdJalmkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/OpenGVLab/InternGPT?style=social" />
          <a href="https://github.com/OpenGVLab/InternGPT" target="_blank">[InternGPT]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/mp4.png">
          <a href="https://igpt.opengvlab.com/" target="_blank">[Demo]</a>
        </div>
      </div>
  </div>

  <hr class="publication-hr">



  </div>

</div>


<!--==========================================
        Oriented Object Detection
===========================================-->
<div class="section publications-section scrollspy" id="ood">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Oriented Object Detection <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/projects.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">AlphaRotate: A Rotation Detection Benchmark using TensorFlow</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Yue Zhou, Wenlong Liao, Tao He, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing <font color="red"><b>(ICASSP, CCF-B)</b></font></em>, Seoul, Korea, 2024</div> 
          <div>
            <a href="https://arxiv.org/abs/2111.06677" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2111.06677-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/AlphaRotate%3A-A-Rotation-Detection-Benchmark-using-Yang-Zhou/7f150cebfbdd2c3a8901a27641f308b34858ea80" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7f150cebfbdd2c3a8901a27641f308b34858ea80%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:dhFuZR0502QC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:dhFuZR0502QC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:dhFuZR0502QC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/docs.png">
            <a href="https://rotationdetection.readthedocs.io/" target="_blank">[docs]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[AlphaRotate-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/h2rbox-v2.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">H2RBox-v2: Incorporating Symmetry for Boosting Horizontal Box Supervised Oriented Object Detection</div>
        <div class="paper-author">Yi Yu<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Qingyun Li, Yue Zhou, Gefan Zhang, Feipeng Da<sup>‚Ä†</sup>, Junchi Yan<sup>‚Ä†</sup></div>
        <div class="paper-conf"><em>Advances in Neural Information Processing Systems <font color="red"><b>(NeurIPS, CCF-A)</b></font></em>, New Orleans, Louisiana, USA, 2023</div> 
        <div>
          <a href="https://arxiv.org/abs/2304.04403" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2304.04403-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:ns9cj8rnVeAC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ns9cj8rnVeAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ns9cj8rnVeAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
          <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[H2RBox-v2-MMRotate]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/620884206" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

  <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/h2rbox.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Gefan Zhang, Wentng Li, Xuehui Wang, Yue Zhou, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>
          <div>
            <a href="https://arxiv.org/abs/2210.06742" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2210.06742-B31B1B.svg" /></a>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:maZDTaKrznsC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:maZDTaKrznsC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:maZDTaKrznsC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-mmrotate?style=social" />
            <a href="https://github.com/yangxue0827/h2rbox-mmrotate" target="_blank">[H2RBox-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[H2RBox-MMRotate]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-jittor?style=social" />
            <a href="https://github.com/yangxue0827/h2rbox-jittor" target="_blank">[H2RBox-Jittor], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[H2RBox-JDet]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/574337609" target="_blank">[Ëß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1614738654315995136" />
            <a href="https://www.zhihu.com/zvideo/1614738654315995136" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GD4y1g7s8" />
            <a href="https://www.bilibili.com/video/BV1GD4y1g7s8" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kfiou.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">The KFIoU Loss for Rotated Object Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Yue Zhou, Gefan Zhang, Jirui Yang, Wentao Wang, Junchi Yan<sup>‚Ä†</sup>, Xiaopeng Zhang, Qi Tian</div>
          <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>

          <div>
            <a href="https://arxiv.org/abs/2201.12558" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2201.12558-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/The-KFIoU-Loss-for-Rotated-Object-Detection-Yang-Zhou/be046653174b9e14c29387ed8e8168ae81c9b5c1" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbe046653174b9e14c29387ed8e8168ae81c9b5c1%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:-f6ydRqryjwC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:-f6ydRqryjwC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:-f6ydRqryjwC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KFIoU-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KFIoU-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[KFIoU-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/463496550" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/gaussian.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Detecting Rotated Objects as Gaussian Distributions and Its 3-D Generalization</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Gefan Zhang, Xiaojiang Yang, Yue Zhou, Wentao Wang, Jin Tang, Tao He, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="red"><b>(TPAMI, CCF-A)</b></font></em>, 2022</div> 
          <div>
              <a href="https://arxiv.org/abs/2209.10839" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2209.10839-B31B1B.svg" /></a>
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:vV6vV6tmYwMC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:vV6vV6tmYwMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:vV6vV6tmYwMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
          </div>  
          <!-- <div> -->
            <!-- <a href="https://yangxue0827.github.io/" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3Acoming.soon-B31B1B.svg" /></a> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://ieeexplore.ieee.org/document/9852282" target="_blank">[paper]</a> -->
          <!-- </div> -->

          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[AlphaRotate], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[MMRotate], </a>
            <img src="https://img.shields.io/github/stars/zhanggefan/mmdet3d-gaussian?style=social" />
            <a href="https://github.com/zhanggefan/mmdet3d-gaussian" target="_blank">[mmdet3d-gaussian], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[JDet]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/372357305" target="_blank">[GWDËß£ËØª], </a>
            <a href="https://zhuanlan.zhihu.com/p/380016283" target="_blank">[KLDËß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/mmrotate.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">MMRotate: A Rotated Object Detection Benchmark using PyTorch</div>
            <div class="paper-author">Yue Zhou<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang<sup>‚Ä†</sup>, Xingzhao Liu, Junchi Yan<sup>‚Ä†</sup>, Chengqi Lyu, Wenwei Zhang, Kai Chen</div>
            <div class="paper-conf">In <em>Proceedings of the 30th ACM International Conference on Multimedia <font color="red"><b>(ACM MM, CCF-A)</b></font></em>, Lisboa, Portugal, Open Source Software Competition, <font color="red"><b>Oral</b></font>, 2022</div> 
            <div>
              <a href="https://arxiv.org/abs/2204.13317" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2204.13317-B31B1B.svg" /></a>
              <!-- <a href="https://www.semanticscholar.org/paper/MMRotate%3A-A-Rotated-Object-Detection-Benchmark-Zhou-Yang/3df973b157132c46f299787d2c5852059d6ce68b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3df973b157132c46f299787d2c5852059d6ce68b%3Ffields%3DcitationCount" /></a> -->
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:_Qo2XoVZTnwC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:_Qo2XoVZTnwC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:_Qo2XoVZTnwC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
            </div>
            <div>
              <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
              <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[MMRotate]</a>
            </div>
            <div>
              <img class="responsive-img icon" src="./images/mp4.png">
              <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548541&file=MM22-mmos06.mp4&download=true" target="_blank">[Video]</a>
            </div>

          </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet++.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Wenlong Liao, Xiaokang Yang, Jin Tang, Tao He</div>
          <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="red"><b>(TPAMI, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2004.13316" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2004.13316-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/SCRDet%2B%2B%3A-Detecting-Small%2C-Cluttered-and-Rotated-Yang-Yan/881bb1d8062529a8a6e42b85345ce99f6bf93175" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F881bb1d8062529a8a6e42b85345ce99f6bf93175%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:lSLTfruPkqcC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:lSLTfruPkqcC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:lSLTfruPkqcC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Hot Cited Paper, ESI Highly Cited Paper</b></font></em></a>
          </div>          
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/DOTA-DOAI?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/DOTA-DOAI" target="_blank">[DOTA-DOAI]</a>

          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="https://github.com/Thinklab-SJTU/S2TLD" target="_blank">[S<sup>2</sup>TLD]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./SCRDet++.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl_gcl_ohdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>International Journal of Computer Vision <font color="red"><b>(IJCV, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <a href="https://arxiv.org/abs/2003.05597" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/On-the-Arbitrary-Oriented-Object-Detection%3A-Based-Yang-Yan/94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:RHpTSmoSYBkC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RHpTSmoSYBkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RHpTSmoSYBkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-TF], </a>
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/OHDet_Tensorflow?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/OHDet_Tensorflow" target="_blank">[OHDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="OHD-SJTU.html" target="_blank">[OHD-SJTU]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./CSL_GCL_OHDet.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kld.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Xiaojiang Yang, Jirui Yang, Qi Ming, Wentao Wang, Qi Tian, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>Advances in Neural Information Processing Systems <font color="red"><b>(NeurIPS, CCF-A)</b></font></em>, Virtual, 2021</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2106.01883" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2106.01883-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Learning-High-Precision-Bounding-Box-for-Rotated-Yang-Yang/81150a2746b1696482ca6fa7157e71b82c7ff530" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F81150a2746b1696482ca6fa7157e71b82c7ff530%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:hC7cP41nSMkC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:hC7cP41nSMkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:hC7cP41nSMkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KLD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KLD-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[KLD-Jittor]</a>
          </div>
           <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/kld_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/neurips21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/380016283" target="_blank">[Ëß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/gwd.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Qi Ming, Wentao Wang, Xiaopeng Zhang, Qi Tian</div>
          <div class="paper-conf">In <em>International Conference on Machine Learning <font color="red"><b>(ICML, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2101.11952" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.11952-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Rethinking-Rotated-Object-Detection-with-Gaussian-Yang-Yan/1b47ee25d1b078368813a417fbe73ceb290e4035" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b47ee25d1b078368813a417fbe73ceb290e4035%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:qUcmZB5y_30C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:qUcmZB5y_30C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:qUcmZB5y_30C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[GWD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[GWD-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[GWD-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/gwd_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/icml21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/372357305" target="_blank">[Ëß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/dcl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Dense Label Encoding for Boundary Discontinuity Free Rotation Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Liping Hou, Yue Zhou, Wentao Wang, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2011.09670" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2011.09670-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Dense-Label-Encoding-for-Boundary-Discontinuity-Yang-Hou/729559024cc246c4bb7b33e395d2957b27662eb4" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F729559024cc246c4bb7b33e395d2957b27662eb4%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:9ZlFYXVOiuMC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9ZlFYXVOiuMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9ZlFYXVOiuMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[RetinaNet-DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[R<sup>3</sup>Det-DCL-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/dcl_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/cvpr21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/354373013" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rsdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning Modulated Loss for Rotated Object Detection</div>
          <div class="paper-author">Wen Qian, <font color="#0000dd"><b>Xue Yang</b></font>, Silong Peng<sup>‚Ä†</sup>, Junchi Yan, Yue Guo</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://arxiv.org/abs/1911.08299" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1911.08299" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1911.08299-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Learning-Modulated-Loss-for-Rotated-Object-Qian-Yang/7322a4580299b322223730ca714a0a951788853a" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7322a4580299b322223730ca714a0a951788853a%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:7PzlFSSx8tAC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:7PzlFSSx8tAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:7PzlFSSx8tAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 10</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet-TF]</a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[RSDet-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/rsdet_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_qw_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/108185873" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/r3det.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">R<sup>3</sup>Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Ziming Feng, Tao He</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1908.05612" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1908.05612-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/R3Det%3A-Refined-Single-Stage-Detector-with-Feature-Yang-Liu/edada2363969e3929366df06aad8a8e9c73ba32f" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fedada2363969e3929366df06aad8a8e9c73ba32f%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:Tyk-4Ss8FVUC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Tyk-4Ss8FVUC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Tyk-4Ss8FVUC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 1</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/R3Det_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/R3Det_Tensorflow" target="_blank">[R<sup>3</sup>Det-TF], </a>
            <!-- <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-on-mmdetection?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-pytorch?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a> -->
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[R<sup>3</sup>Det-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/r3det_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_yx_poster.pdf" target="_blank">[poster], </a>
            <a href="http://engine.scichina.com/doi/10.1360/SSI-2022-0410" target="_blank">[ÊúüÂàäÁâàÊú¨„Ää‰∏≠ÂõΩÁßëÂ≠¶Ôºö‰ø°ÊÅØÁßëÂ≠¶„Äã]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Arbitrary-Oriented Object Detection with Circular Smooth Label</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the European Conference on Computer Vision <font color="red"><b>(ECCV, CCF-B, Tsinghua-A)</b></font></em>, Glasgow, Scotland, UK (Virtual), 2020</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-58598-3_40" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Arbitrary-Oriented-Object-Detection-with-Circular-Yang-Yan/feb6f9d7082d29dbf4d6c1bb70b404f7237298b6" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffeb6f9d7082d29dbf4d6c1bb70b404f7237298b6%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:WF5omc3nYNoC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:WF5omc3nYNoC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:WF5omc3nYNoC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-RetinaNet-TF]</a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[CSL-RetinaNet-PyTorch]</a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[CSL-RetinaNet-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/2003.05597" target="_blank">paper,</a> -->
            <a href="./files/csl_slides.pdf" target="_blank">[slides]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/111493759" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Jirui Yang, Junchi Yan<sup>‚Ä†</sup>, Yue Zhang, Tengfei Zhang, Zhi Guo, Sun Xian, Kun Fu</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Seoul, Korea, 2019</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1811.07126" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1811.07126-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/SCRDet%3A-Towards-More-Robust-Detection-for-Small%2C-Yang-Yang/456b8ae5dd6f8316c1fda46c5a8b4204c10ae320" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F456b8ae5dd6f8316c1fda46c5a8b4204c10ae320%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:9yKSN-GCB0IC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9yKSN-GCB0IC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9yKSN-GCB0IC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF],</a>
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow" target="_blank">[R<sup>2</sup>CNN++-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/1811.07126" target="_blank">paper,</a> -->
            <a href="./files/iccv_2019_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/107400817" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rdfpn.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Automatic Ship Detection in Remote Sensing Images from Google Earth of Complex Scenes Based on Multiscale Rotation Dense Feature Pyramid Networks</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Hao Sun, Kun Fu<sup>‚Ä†</sup>, Jirui Yang, Xian Sun, Menglong Yan, Zhi Guo</div>
          <div class="paper-conf">In <em>Remote Sensing</em>, 2018</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1806.04331" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1806.04331-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Automatic-Ship-Detection-in-Remote-Sensing-Images-Yang-Sun/dad0e3d7b1dc51196255ba220ed58ff29aa7c92b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdad0e3d7b1dc51196255ba220ed58ff29aa7c92b%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:bEWYMUwI8FkC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:bEWYMUwI8FkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:bEWYMUwI8FkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
          </div>
          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://www.mdpi.com/2072-4292/10/1/132" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/R-DFPN_FPN_Tensorflow?style=social" />
            <a href="https://github.com/yangxue0827/R-DFPN_FPN_Tensorflow" target="_blank">[R-DFPN-TF]</a>
          </div>
        </div>
      </div>
      <hr class="publication-hr">

      <div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div>
  </div>


</div>


<!--==========================================
  Object Detection and Instance Segmentation
===========================================-->
<div class="section preprints-section scrollspy" id="ob_and_is">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Object Detection and Instance Segmentation <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/patchdct.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">PatchDCT: Patch Refinement for High Quality Instance Segmentation</div>
        <div class="paper-author">Qinrou Wen, Jirui Yang, <font color="#0000dd"><b>Xue Yang</b></font>, Kewei Liang<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>
        <div>
          <a href="https://arxiv.org/abs/2302.02693" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2302.02693-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:YFjsv_pBGBYC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:YFjsv_pBGBYC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:YFjsv_pBGBYC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <!-- <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://openreview.net/forum?id=t9Zd7Oi5JPl" target="_blank">[paper]</a>
        </div> -->
        <div>
          <img src="https://img.shields.io/github/stars/olivia-w12/PatchDCT?style=social" />
          <a href="https://github.com/olivia-w12/PatchDCT" target="_blank">[PatchDCT-PyTorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/607624400" target="_blank">[Ëß£ËØª], </a>
          <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1622336916027785216" />
          <a href="https://www.zhihu.com/zvideo/1622336916027785216" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
        </div>
        <div>
          <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Sx4y1w7JK" />
          <a href="https://www.bilibili.com/video/BV1Sx4y1w7JK" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">


  </div>

</div>

<!--==========================================
    Scene Text Detection and Recognition
===========================================-->
<div class="section preprints-section scrollspy" id="ocr">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Scene Text Detection and Recognition <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ccd.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Self-supervised Character-to-Character Distillation for Text Recognition</div>
        <div class="paper-author">Tongkun Guan, Wei Shen<sup>‚Ä†</sup>, <font color="#0000dd"><b>Xue Yang</b></font>, Qi Feng, Zekun Jiang, Xiaokang Yang</div>
        <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Paris, France, 2023</div>
        <div>
          <a href="https://arxiv.org/abs/2211.00288" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2111.06677-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:GnPB-g6toBAC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:GnPB-g6toBAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:GnPB-g6toBAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
            <img src="https://img.shields.io/github/stars/TongkunGuan/CCD?style=social" />
            <a href="https://github.com/TongkunGuan/CCD" target="_blank">[CCD-PyTorch]</a>
        </div>
        <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/644350078" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/gten.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Self-supervised Implicit Glyph Attention for Text Recognition</div>
        <div class="paper-author">Tongkun Guan, Chaochen Gu<sup>‚Ä†</sup>, Jingzheng Tu, <font color="#0000dd"><b>Xue Yang</b></font>, Qi Feng, Yudi Zhao, Wei Shen<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Vancouver, Canada, 2023</div> 
        <div>
          <a href="https://arxiv.org/abs/2203.03382" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2203.03382-B31B1B.svg" /></a>
          <!-- <a href="https://www.semanticscholar.org/paper/A-Glyph-driven-Topology-Enhancement-Network-for-Guan-Gu/1eb445c6ccb839002b22d6ba05a6d3a83aac8372" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1eb445c6ccb839002b22d6ba05a6d3a83aac8372%3Ffields%3DcitationCount" /></a> -->
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:isC4tDSrTZIC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:isC4tDSrTZIC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:isC4tDSrTZIC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/TongkunGuan/SIGA?style=social" />
          <a href="https://github.com/TongkunGuan/SIGA" target="_blank">[SIGA-PyTorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/644350078" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

  <hr class="publication-hr">


  </div>

</div>

<!--==========================================
                Low-Level Vision
===========================================-->
<div class="section preprints-section scrollspy" id="low_level">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Low-Level Vision <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9">[Full List]</font> </a></div>
      <hr>
    </div>

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/wwt_cvpr22.jpg">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">Dual-path Image Inpainting with Auxiliary GAN Inversion</div>
      <div class="paper-author">Wentao Wang, Li Niu<sup>‚Ä†</sup>, Jianfu Zhang, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang<sup>‚Ä†</sup></div>
      <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, New Orleans, Louisiana, USA, 2022</div> 
      <div>
        <!-- <a href="https://www.semanticscholar.org/paper/Dual-path-Image-Inpainting-with-Auxiliary-GAN-Wang-Niu/9e93ea471ade297fa55d836241428e2174d43fbe" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9e93ea471ade297fa55d836241428e2174d43fbe%3Ffields%3DcitationCount" /></a> -->
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:r0BpntZqJG4C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
      </div>
      <div>
        <img class="responsive-img icon" src="./images/pdf.png">
        <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.html" target="_blank">[paper], </a>
        <a href="./files/cvpr22_inp_poster.pdf" target="_blank">[poster]</a>
    </div>
    </div>
  </div>

  <hr class="publication-hr">

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/pmrfnet.jpeg">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">Parallel Multi-Resolution Fusion Network for Image Inpainting</div>
      <div class="paper-author">Wentao Wang, Jianfu Zhang, Li Niu<sup>‚Ä†</sup>, Haoyu Ling, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang<sup>‚Ä†</sup></div>
      <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Virtual, 2021</div>
      <div>
        <!-- <a href="https://www.semanticscholar.org/paper/Parallel-Multi-Resolution-Fusion-Network-for-Image-Wang-Zhang/320335cd05e98089de35057348498000d3130429" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F320335cd05e98089de35057348498000d3130429%3Ffields%3DcitationCount" /></a> -->
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:mVmsd5A6BfQC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:mVmsd5A6BfQC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:mVmsd5A6BfQC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
      </div> 
      <div>
        <img class="responsive-img icon" src="./images/pdf.png">
        <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Parallel_Multi-Resolution_Fusion_Network_for_Image_Inpainting_ICCV_2021_paper.pdf" target="_blank">[paper], </a>
        <a href="./files/iccv21_wwt_poster.pdf" target="_blank">[poster]</a>
      </div>
    </div>
  </div>

  <hr class="publication-hr">


  </div>

</div>

<!-- ==========================================
                   Activities
=========================================== -->
<div class="section activities-section scrollspy" id="activities">
  <div class="row container">
    <div class="row">
      <div class="title">üìö Academic Activities</div>
      <hr>

        <h5>Conference Reviewers</h5>
        <ul>
          <li>‚ÄÉ ‚Ä¢ IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021-2024</li>
          <li>‚ÄÉ ‚Ä¢ IEEE/CVF International Conference on Computer Vision (ICCV), 2023</li>
          <li>‚ÄÉ ‚Ä¢ European Conference on Computer Vision (ECCV), 2022/2024</li>
          <li>‚ÄÉ ‚Ä¢ Neural Information Processing Systems (NeurIPS), 2022-2023</li>
          <li>‚ÄÉ ‚Ä¢ International Conference on Machine Learning (ICML), 2022-2024</li>
          <li>‚ÄÉ ‚Ä¢ International Conference on Learning Representations (ICLR), 2024</li>
          <li>‚ÄÉ ‚Ä¢ AAAI Conference on Artificial Intelligence (AAAI), 2022-2024</li>
          <li>‚ÄÉ ‚Ä¢ ACM International Conference on Multimedia (ACM MM), 2021-2023</li>
        </ul>

        <h5>Journal Reviewers</h5>
        <ul>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
          <li>‚ÄÉ ‚Ä¢ International Journal of Computer Vision (IJCV)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Image Processing (TIP)</li>
          <li>‚ÄÉ ‚Ä¢ Pattern Recognition (PR)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Geoscience and Remote Sensing Letters (GRSL)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Intelligent Transportation Systems (TITS)</li>
          <li>‚ÄÉ ‚Ä¢ IEEE Transactions on Multimedia Computing Communications and Applications (TOMM)</li>
          <li>‚ÄÉ ‚Ä¢ Remote Sensing</li>
        </ul>

        <h5>Tech. Talks</h5>
        <ul>
          <li>‚ÄÉ ‚Ä¢ 06 / 2023: &nbsp; Valse 2023 Wuxi <a href="http://valser.org/2023/#/workshop" target="_blank">[Valse 2023 Êó†Èî°, W2ÔºöÈÅ•ÊÑüÂΩ±ÂÉèËß£ËØë]</a>, <a href="./files/VALSE 2023 Wuxi.pdf" target="_blank">[Êä•ÂëäPPT]</a>, <a href="https://www.bilibili.com/video/BV1yu4y1R7f6/?spm_id_from=333.788&vd_source=be89b0c65eab470db155c6731fcffddf">[Êä•ÂëäÂõûÊîæ]</a> </li>
          <li>‚ÄÉ ‚Ä¢ 03 / 2023: &nbsp; OpenMMLab <a href="https://mp.weixin.qq.com/s/eoSxS64EtyF8FRMd3BlS-w" target="_blank">[OpenMMLabÁ§æÂå∫ÂºÄÊîæÈ∫¶]</a>, <a href="./files/OpenMMLabÂºÄÊîæÈ∫¶20230302.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1GD4y1g7s8" target="_blank">[bilibili playback]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GD4y1g7s8" />, <a href="https://www.zhihu.com/zvideo/1614738654315995136" target="_blank">[zhihu playback]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1614738654315995136" /></li>
          <li>‚ÄÉ ‚Ä¢ 12 / 2022: &nbsp; Doctoral Forum of PRCV 2022 <a href="https://m.inmuu.com/v1/live/news/2265574?gatherId=4043" target="_blank">[PRCV 2022 ÂçöÂ£´ÁîüËÆ∫Âùõ]</a></li>
          <li>‚ÄÉ ‚Ä¢ 07 / 2022: &nbsp; OpenMMLab <a href="https://mp.weixin.qq.com/s/-_x4URDyhwqNC4mD_0daDw" target="_blank">[OpenMMLabÁ§æÂå∫ÂºÄÊîæÈ∫¶]</a>, <a href="./files/OpenMMLabÂºÄÊîæÈ∫¶.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[bilibili playback]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />, <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[zhihu playback]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" /></li>
          <li>‚ÄÉ ‚Ä¢ 06 / 2022: &nbsp; Young Scholars Forum of Wu Wenjun's artificial intelligence doctoral class <a href="https://mp.weixin.qq.com/s/lg1vNIZYqnDfq9SC93OT3A" target="_blank">[Âê¥Áè≠Talk]</a>, <a href="./files/Âê¥Áè≠Talk.pdf" target="_blank">[slides]</a></li>
          <li>‚ÄÉ ‚Ä¢ 12 / 2021: &nbsp; The fifth Jittor Forum <a href="https://mp.weixin.qq.com/s/8pYzCYU25B8Zzk78NBoovw" target="_blank">[Á¨¨‰∫îÊúü‚ÄúËÆ°Âõæ‚ÄùËÆ∫Âùõ]</a>, <a href="./files/ËÆ°ÂõæËÆ∫Âùõ.pdf" target="_blank">[slides]</a></li>
          <li>‚ÄÉ ‚Ä¢ 05 / 2021: &nbsp; Magnolia Young Scholar Forum <a href="https://www.slidestalk.com/w/409" target="_blank">[ÁôΩÁéâÂÖ∞ÈùíÂπ¥Â≠¶ËÄÖËÆ∫Âùõ]</a>, <a href="./files/ÊóãËΩ¨ÁõÆÊ†áÊ£ÄÊµã-ÁôΩÁéâÂÖ∞ÈùíÂπ¥Â≠¶ËÄÖËÆ∫Âùõ.pdf" target="_blank">[slides]</a></li>
        </ul>

    </div>
  </div>
</div>


<!--==========================================
                   Education
===========================================-->
<div class="section education-section scrollspy" id="education">
  <div class="row container">
    <div class="row">
      <div class="title">üéì Education</div>
      <hr>
    </div>
    
    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="http://www.csu.edu.cn/" target="_blank">
            <img src="./images/csu.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>B.E.</b> degree from School of Information Science and Engineering, <a href="http://www.csu.edu.cn/">Central South University</a>, Hunan, China</div>
          <div class="date">Sep. 2012 - July 2016</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://eece.ucas.ac.cn/index.php/zh-cn/" target="_blank">
            <img src="./images/ucas.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
            <!-- <img src="./images/iecas.jpeg" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/air.png" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>M.S.</b> degree from <a href="https://eece.ucas.ac.cn/index.php/zh-cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a><!--  (<a href="http://aircas.ac.cn/">Institute of Electrics, Chinese Academy of Sciences</a>) -->, Beijing, China</div>
          <div class="date">Sep. 2016 - July 2019</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="ttp://en.sjtu.edu.cn" target="_blank">
            <img src="./images/sjtu.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"><b>Ph.D.</b> in CV, Department of Computer Science and Engineering</a>, <a href="http://en.sjtu.edu.cn">Shanghai Jiao Tong University</a>, Shanghai, China</div>
          <div class="date">Sep. 2019 - July 2023</div>
        </div>
    </div>
  </div>
</div>


<div class="section preprints-section scrollspy" id="internship">

  <div class="row container">
    <div class="row">
      <div class="title">üßëüèª‚Äçüíª Internship and Cooperation</div>
      <hr>
    </div>

        <div class="corp_item">
          <img class="corp_logo" style="height:80px;" src="./images/samsung.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/megvii.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/tencentmap.png"> &nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:110px;" src="./images/huawei.png"> -->
          <img class="corp_logo" style="height:80px;" src="./images/huawei1.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:60px;" src="./images/pjlab.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/openmmlab.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/opengvlab.png"> 
        </div>

  </div>

</div>


<!-- ==========================================
                   Awards
=========================================== -->
<div class="section awards-section scrollspy" id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">üéñ Awards</div>      
      <hr>
      <ul>
        <li>‚ÄÉ ‚Ä¢ <a href="https://mp.weixin.qq.com/s/Hk8iKReAUJVB_CraXqWYKg" target="_blank">CCF Outstanding Doctoral Dissertation Award</a>, only nine winners in China, 2023</li>
        <li>‚ÄÉ ‚Ä¢ <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6">World's Top 2% Scientists List</a>, 2022/2023</li>
        <li>‚ÄÉ ‚Ä¢ Shanghai Outstanding Graduates, 2023</li>
        <li>‚ÄÉ ‚Ä¢ <a href="https://mp.weixin.qq.com/s/mUgpVmyvCHdo5-T6-u8Yxg">CCF-CV Academic Emerging Scholar</a>, only three winners in China, 2022</li>
        <li>‚ÄÉ ‚Ä¢ <a href="https://mp.weixin.qq.com/s/liVosHsotD2zDMyfmTIQJg" target="_blank">Doctoral National Scholarship</a>, 2022</li>
        <li>‚ÄÉ ‚Ä¢ Nominated by <a href="https://mp.weixin.qq.com/s/hr7qtx3OUffSGS9qUhqc9w" target="_blank">SJTU Scholar Star</a>, 10 official and 10 nomination awards in SJTU, 2021</li>
        <li>‚ÄÉ ‚Ä¢ Top 40 in the ninth Baidu Scholarship, 2021</li>
        <li>‚ÄÉ ‚Ä¢ <a href="https://mp.weixin.qq.com/s/ugk1l0QpuzJXaExJ_wH-4w" target="_blank">Doctoral National Scholarship</a>, Top-1 in CSE, 2021</li>
        <li>‚ÄÉ ‚Ä¢ <a href="https://ai.sjtu.edu.cn/info/news/126">Wu Wen Jun Honorary Doctoral Scholarship</a>, 2019</li>
        <li>‚ÄÉ ‚Ä¢ 1st place in <a href="https://gaia.didichuxing.com/d2city">WAD2019 Challenge</a> on the D<sup>2</sup>-City & BDD100K Detection Domain Adaption track, 2019</li>
        <li>‚ÄÉ ‚Ä¢ 3st/4th place in <a href="https://captain-whu.github.io/DOAI2019/results.html">DOAI2019 Challenge</a> on the HBB/OBB track, 2019</li>
        <li>‚ÄÉ ‚Ä¢ Outstanding Student Leader, Outstanding Student, 2016-2019</li>
        <li>‚ÄÉ ‚Ä¢ Outstanding Student Leader, Outstanding Student, Outstanding Graduates, National Inspirational Scholarship, 2012-2016</li>
      </ul>
    </div>
  </div>
</div>

<!-- ==========================================
                   Projects
=========================================== -->
<div class="section preprints-section scrollspy" id="projects">

  <div class="row container">
    <div class="row">
      <div class="title">üõ† Projects</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l9 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/projects.png">
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/yangxue0827" target="_blank">yangxue0827</a><br>
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/DetectionTeamUCAS" target="_blank">DetectionTeamUCAS</a><br>
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/Thinklab-SJTU" target="_blank">Thinklab-SJTU</a><br>
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/SJTU-Thinklab-Det" target="_blank">SJTU-Thinklab-Det</a><br>
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/open-mmlab/mmrotate" target="_blank">open-mmlab/mmrotate</a><br>
      </div>

      <div>
        <img class="responsive-img icon" src="./images/github.png">
        <a href="https://github.com/Jittor/JDet" target="_blank">Jittor/JDet</a><br>
      </div>


  </div>
  <!-- <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:460px;" /> -->
  <!-- <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:460px;" /> -->

</div>


<!-- ==========================================
                   Demo
=========================================== -->
<div class="section awards-section scrollspy" id="demos">
  <div class="row container">
    <div class="row">
      <div class="title">üíª Demos</div>      
      <hr>
      <video width="640" height="480" controls muted>
        <source src="./videos/obsidian_minecraft.mp4" type="video/mp4">
      </video>
      <br>
      <video width="640" height="360" controls muted>
        <source src="https://user-images.githubusercontent.com/10410257/154433305-416d129b-60c8-44c7-9ebb-5ba106d3e9d5.MP4" type="video/mp4">
      </video>
      <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:360px;" />
      <!-- <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:600px;" /> -->
      <!-- <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:600px;" /> -->
      <br>
      <!-- <video width="640" height="360" controls autoplay muted> -->
      <video width="640" height="360" controls muted>
        <source src="./videos/demo.mp4" type="video/mp4">
      </video>
      <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:360px;" /> 
    </div>
  </div>
</div>


<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=yZcblN50sSwsCOVmEPYqkPD6Wo-RFHx0E2yb6Ktm_Wk&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright ¬© Xue Yang 2020
    </div>  
</footer>

<!--  Scripts-->

<!-- <script src="./files/jquery-2.1.1.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>
<script>
    window.onload = function () {
    // $(document).ready(function () {
        var gsDataBaseUrl = 'https://raw.githubusercontent.com/yangxue0827/yangxue0827.github.io/'
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {

            //var totalCitation = data['citedby']
            //document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = numCitations;
            });
        });
    }
</script>

</div><div class="jvectormap-tip"></div></body></html>
